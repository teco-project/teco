//===----------------------------------------------------------------------===//
//
// This source file is part of the Teco open source project
//
// Copyright (c) 2022-2023 the Teco project authors
// Licensed under Apache License v2.0
//
// See LICENSE.txt for license information
//
// SPDX-License-Identifier: Apache-2.0
//
//===----------------------------------------------------------------------===//

// THIS FILE IS AUTOMATICALLY GENERATED by TecoServiceGenerator.
// DO NOT EDIT.

import Logging
import NIOCore
import TecoCore

extension Dlc {
    /// ModifySparkAppBatch请求参数结构体
    public struct ModifySparkAppBatchRequest: TCRequest {
        /// 需要批量修改的Spark作业任务ID列表
        public let sparkAppId: [String]

        /// 引擎ID
        public let dataEngine: String?

        /// driver规格：small,medium,large,xlarge；内存型(引擎类型)：m.small,m.medium,m.large,m.xlarge
        public let appDriverSize: String?

        /// executor规格：small,medium,large,xlarge；内存型(引擎类型)：m.small,m.medium,m.large,m.xlarge
        public let appExecutorSize: String?

        /// 指定executor数量，最小值为1，最大值小于集群规格
        public let appExecutorNums: UInt64?

        /// 指定executor max数量（动态配置场景下），最小值为1，最大值小于集群规格（当ExecutorMaxNumbers小于ExecutorNums时，改值设定为ExecutorNums）
        public let appExecutorMaxNumbers: UInt64?

        /// 任务资源配置是否继承集群模板，0（默认）不继承，1：继承
        public let isInherit: UInt64?

        public init(sparkAppId: [String], dataEngine: String? = nil, appDriverSize: String? = nil, appExecutorSize: String? = nil, appExecutorNums: UInt64? = nil, appExecutorMaxNumbers: UInt64? = nil, isInherit: UInt64? = nil) {
            self.sparkAppId = sparkAppId
            self.dataEngine = dataEngine
            self.appDriverSize = appDriverSize
            self.appExecutorSize = appExecutorSize
            self.appExecutorNums = appExecutorNums
            self.appExecutorMaxNumbers = appExecutorMaxNumbers
            self.isInherit = isInherit
        }

        enum CodingKeys: String, CodingKey {
            case sparkAppId = "SparkAppId"
            case dataEngine = "DataEngine"
            case appDriverSize = "AppDriverSize"
            case appExecutorSize = "AppExecutorSize"
            case appExecutorNums = "AppExecutorNums"
            case appExecutorMaxNumbers = "AppExecutorMaxNumbers"
            case isInherit = "IsInherit"
        }
    }

    /// ModifySparkAppBatch返回参数结构体
    public struct ModifySparkAppBatchResponse: TCResponse {
        /// 唯一请求 ID，每次请求都会返回。定位问题时需要提供该次请求的 RequestId。
        public let requestId: String

        enum CodingKeys: String, CodingKey {
            case requestId = "RequestId"
        }
    }

    /// 批量修改Spark作业参数配置
    ///
    /// 本接口（ModifySparkAppBatch）用于批量修改Spark作业参数配置
    @inlinable @discardableResult
    public func modifySparkAppBatch(_ input: ModifySparkAppBatchRequest, region: TCRegion? = nil, logger: Logger = TCClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ModifySparkAppBatchResponse> {
        self.client.execute(action: "ModifySparkAppBatch", region: region, serviceConfig: self.config, input: input, logger: logger, on: eventLoop)
    }

    /// 批量修改Spark作业参数配置
    ///
    /// 本接口（ModifySparkAppBatch）用于批量修改Spark作业参数配置
    @inlinable @discardableResult
    public func modifySparkAppBatch(_ input: ModifySparkAppBatchRequest, region: TCRegion? = nil, logger: Logger = TCClient.loggingDisabled, on eventLoop: EventLoop? = nil) async throws -> ModifySparkAppBatchResponse {
        try await self.client.execute(action: "ModifySparkAppBatch", region: region, serviceConfig: self.config, input: input, logger: logger, on: eventLoop).get()
    }

    /// 批量修改Spark作业参数配置
    ///
    /// 本接口（ModifySparkAppBatch）用于批量修改Spark作业参数配置
    @inlinable @discardableResult
    public func modifySparkAppBatch(sparkAppId: [String], dataEngine: String? = nil, appDriverSize: String? = nil, appExecutorSize: String? = nil, appExecutorNums: UInt64? = nil, appExecutorMaxNumbers: UInt64? = nil, isInherit: UInt64? = nil, region: TCRegion? = nil, logger: Logger = TCClient.loggingDisabled, on eventLoop: EventLoop? = nil) -> EventLoopFuture<ModifySparkAppBatchResponse> {
        self.modifySparkAppBatch(.init(sparkAppId: sparkAppId, dataEngine: dataEngine, appDriverSize: appDriverSize, appExecutorSize: appExecutorSize, appExecutorNums: appExecutorNums, appExecutorMaxNumbers: appExecutorMaxNumbers, isInherit: isInherit), region: region, logger: logger, on: eventLoop)
    }

    /// 批量修改Spark作业参数配置
    ///
    /// 本接口（ModifySparkAppBatch）用于批量修改Spark作业参数配置
    @inlinable @discardableResult
    public func modifySparkAppBatch(sparkAppId: [String], dataEngine: String? = nil, appDriverSize: String? = nil, appExecutorSize: String? = nil, appExecutorNums: UInt64? = nil, appExecutorMaxNumbers: UInt64? = nil, isInherit: UInt64? = nil, region: TCRegion? = nil, logger: Logger = TCClient.loggingDisabled, on eventLoop: EventLoop? = nil) async throws -> ModifySparkAppBatchResponse {
        try await self.modifySparkAppBatch(.init(sparkAppId: sparkAppId, dataEngine: dataEngine, appDriverSize: appDriverSize, appExecutorSize: appExecutorSize, appExecutorNums: appExecutorNums, appExecutorMaxNumbers: appExecutorMaxNumbers, isInherit: isInherit), region: region, logger: logger, on: eventLoop)
    }
}
